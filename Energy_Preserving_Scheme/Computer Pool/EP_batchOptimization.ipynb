{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "4 4\n",
      "4 4\n",
      "(40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True) \n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import prk_for_optimization as IRK4\n",
    "import Transformation_Functions as TFunctions\n",
    "import Initial_weights\n",
    "import Generate_HaltonSequence\n",
    "import Convert_1D2D as convert\n",
    "import Save_Results\n",
    "\n",
    "# Initial Weights\n",
    "A1, A2, B1, B2 = Initial_weights.Lobatto3A3B_4thOrder()\n",
    "\n",
    "# Making the Halton code\n",
    "halton_sequence = Generate_HaltonSequence.Halton_Sequence(150)\n",
    "flat_halton_sequence = jnp.array(halton_sequence).reshape(-1, 6)\n",
    "\n",
    "validation_halton = halton_sequence[100:150]\n",
    "halton_sequence = halton_sequence[:100]\n",
    "\n",
    "# # Making a 1D array\n",
    "# A1D = Convert_1D2D.Convert_toOneD(A1, A2, B1, B2)\n",
    "# print(A1D.shape)\n",
    "\n",
    "# list_optimizers = [optax.adam(learning_rate)]\n",
    "# opt_sgd = list_optimizers[0]\n",
    "# opt_state = opt_sgd.init(A1D)\n",
    "# params = A1D\n",
    "# error_list_1, error_list_2 = [], []\n",
    "# learning_rate, batch_size = 0.1, 100\n",
    "\n",
    "\n",
    "A1D = convert.Convert_toOneD(A1, A2, B1, B2)\n",
    "print(A1D.shape)\n",
    "\n",
    "learning_rate = 0.01\n",
    "list_optimizers = [optax.sgd(learning_rate)]\n",
    "# chosing Stochastic Gradient Descent Algorithm.\n",
    "# # We have created a list here keeping in mind that we may apply all the optimizers in optax by storing their objects in the list\n",
    " \n",
    "opt_sgd = list_optimizers[0]\n",
    "opt_state = opt_sgd.init(A1D)\n",
    "\n",
    "params = A1D\n",
    "\n",
    "count = 0\n",
    "data_epoc = 10\n",
    "data_epoc_list = []\n",
    "repetetion = 10\n",
    "# length of halton sequence = 10 \n",
    "\n",
    "tot_eror = 0\n",
    "error_list_1 = [] \n",
    "error_list_2 = []\n",
    "validation_error_list = []\n",
    "validation_tot_error = 0\n",
    "validation_avg_error = 0\n",
    "\n",
    "flat_halton_sequence = jnp.array(halton_sequence).reshape(-1, 6)\n",
    "\n",
    "batch_size = 100\n",
    "validation_batch_size = 50\n",
    "\n",
    "directory = 'Recorded_Results_SGD2'\n",
    "if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "file_path1 = os.path.join(directory, 'output.txt')\n",
    "# Open the file in write mode to clear it\n",
    "with open(file_path1, 'w') as file:\n",
    "    pass  # This does nothing, but it's enough to clear the file\n",
    "\n",
    "def compute_grads_single(A1D, h_element):\n",
    "    grad_fn = jax.jacfwd(IRK4.find_error)\n",
    "    return grad_fn(A1D, h_element)\n",
    "\n",
    "def compute_error_single(A1D, h_element):\n",
    "    return IRK4.find_error(A1D, h_element)\n",
    "\n",
    "def append_to_summary(k, avg_error):\n",
    "    file_path = os.path.join(directory, f'Step_error.txt')\n",
    "    \n",
    "    # # Define the file name\n",
    "    # file_name = '0_summary_sgd2.txt'\n",
    "\n",
    "    # Append the data to the text file\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(f'{k} : {avg_error}\\n')\n",
    "\n",
    "# Use jax.vmap to vectorize the function over the batch\n",
    "compute_grads_batched = jax.vmap(compute_grads_single, in_axes=(None, 0))\n",
    "compute_error_batched = jax.vmap(compute_error_single, in_axes=(None, 0))\n",
    "\n",
    "for k in trange(10):\n",
    "    tot_error = 0\n",
    "    for batch_idx in range(0, len(flat_halton_sequence), batch_size):\n",
    "        batch_halton = flat_halton_sequence[batch_idx:batch_idx + batch_size]\n",
    "        gradF = compute_grads_batched(A1D, batch_halton)\n",
    "        avg_gradF = jnp.mean(gradF, axis=0)\n",
    "        updates, opt_state = opt_sgd.update(avg_gradF, opt_state)\n",
    "        \n",
    "        A1D = optax.apply_updates(A1D, updates)\n",
    "        batch_error = jnp.mean(compute_error_batched(A1D, batch_halton))\n",
    "        tot_error += batch_error\n",
    "\n",
    "    avg_error = tot_error / (len(flat_halton_sequence) // batch_size)\n",
    "    error_list_1.append(avg_error)\n",
    "  \n",
    "    \"\"\"\n",
    "    ------------------------------- Substitute -------------------\n",
    "    \"\"\"\n",
    "    # tot_error = 0\n",
    "    # for mm in range(len(halton_sequence)):\n",
    "    #     tot_error += IRK4.find_error(A1D, halton_sequence[mm])\n",
    "  \n",
    "    # error_list_2.append(tot_error / len(halton_sequence))\n",
    "    # A1D = A1D[:40]\n",
    "    \n",
    "    # # Converting A1D list, to individual A1, A2, B1 and B2\n",
    "    # new_A1, new_A2, new_B1, new_B2 = Convert_1D2D.Convert_toOneD(A1D)\n",
    "\n",
    "    # # Saving to a json file\n",
    "    # Save_Results.Save_json(new_A1, new_A2, new_B1, new_B2, avg_error, k)\n",
    "      \n",
    "    # # Saving updated weights in different .txt files\n",
    "    # Save_Results.Save_UpdatedWeights(new_A1, new_A2, new_B1, new_B2, avg_error, k)\n",
    "    \n",
    "    # # Saving epochs, error to a .txt file\n",
    "    # Save_Results.Save_Error(avg_error, k)\n",
    "    \n",
    "    \"\"\"\n",
    "    ------------------------------- Substitute -------------------\n",
    "    \"\"\"\n",
    "\n",
    "    tot_error = 0\n",
    "    for mm in range(len(halton_sequence)):\n",
    "        tot_error += IRK4.find_error(A1D, halton_sequence[mm])\n",
    "    \n",
    "    avg_error = tot_error / len(halton_sequence)\n",
    "    error_list_2.append(avg_error)\n",
    "    \n",
    "    # Validation data set\n",
    "    for mm in range(0,len(validation_halton)):\n",
    "        validation_tot_error += IRK4.find_error(A1D, validation_halton[mm])\n",
    "    \n",
    "    validation_avg_error = validation_tot_error / len(validation_halton)\n",
    "    validation_error_list.append(validation_avg_error)\n",
    "    \n",
    "    \n",
    "    A1D = A1D[:40]\n",
    "    \n",
    "    ##################################################################################\n",
    "    new_A1, new_A2, new_B1, new_B2 = convert.Convert_toTwoD(A1D)\n",
    "    \n",
    "    # Create a directory if it doesn't exist\n",
    "    directory = 'Recorded_Results_SGD2'\n",
    "    \n",
    "    # Define the file path based on the value of k\n",
    "    file_path = os.path.join(directory, f'BatchOutput_SGD2.json')\n",
    "    \n",
    "    # Saving to a json file.\n",
    "    json_A1 = new_A1.tolist()\n",
    "    json_A2 = new_A2.tolist()\n",
    "    json_B1 = new_B1.tolist()\n",
    "    json_B2 = new_B2.tolist()\n",
    "    json_avg_error = float(avg_error)\n",
    "    # Combine data into a dictionary\n",
    "    data = {\n",
    "        'Number' : k,\n",
    "        'Error' : json_avg_error,\n",
    "        'A1': json_A1,\n",
    "        'A2': json_A2,\n",
    "        'B1': json_B1,\n",
    "        'B2': json_B2 \n",
    "    }\n",
    "    \n",
    "    # try:\n",
    "    #     with open(file_path, 'r') as file:\n",
    "    #         existing_data = json.load(file)\n",
    "    # except FileNotFoundError:\n",
    "    #     existing_data = []\n",
    "\n",
    "    # existing_data.append(data)\n",
    "    \n",
    "    # Save the data to BatchOutput.json\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "    # print(f'Data saved to {file_path}')\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    \"\"\"Creating new files for all the new A1, A2, B1 and B2 values\"\"\"\n",
    "    \n",
    "    # Assuming you have the necessary data (new_A1, new_A2, new_B1, new_B2, avg_error, k)\n",
    "\n",
    "    # Convert lists to strings\n",
    "    A1_str = ' - '.join(map(str, new_A1.tolist()))\n",
    "    A2_str = ' - '.join(map(str, new_A2.tolist()))\n",
    "    B1_str = ' - '.join(map(str, new_B1.tolist()))\n",
    "    B2_str = ' - '.join(map(str, new_B2.tolist()))\n",
    "\n",
    "    # Convert avg_error to a float (if necessary)\n",
    "    avg_error_float = float(avg_error) if avg_error.shape == () else avg_error.tolist() ## this line not added to the pool file.. SaveResults\n",
    "\n",
    "    # Convert k to an integer (if it's not already)\n",
    "    json_k = int(k)\n",
    "\n",
    "    \n",
    "    # Define the file path based on the value of k\n",
    "    file_path = os.path.join(directory, f'output.txt')\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    # Read existing content (if any)\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            existing_content = file.read()\n",
    "    except FileNotFoundError:\n",
    "        existing_content = ''\n",
    "\n",
    "\n",
    "    # Write the data to the text file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(existing_content)\n",
    "        file.write(f'Number: {json_k}\\n')\n",
    "        file.write(f'Error: {avg_error_float}\\n')\n",
    "        file.write(f'A1: {A1_str}\\n')\n",
    "        file.write(f'A2: {A2_str}\\n')\n",
    "        file.write(f'B1: {B1_str}\\n')\n",
    "        file.write(f'B2: {B2_str}\\n')\n",
    "        file.write('-' * 80 + '\\n')  # Add a division line\n",
    "    \n",
    "    \"\"\"Creating a single file for sequence number and error associated with it. \"\"\"\n",
    "    append_to_summary(k, avg_error_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
